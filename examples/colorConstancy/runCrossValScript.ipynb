{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the trainning and validation set file \n",
    "1. list txt for training and validation\n",
    "2. h5 file for training and validation\n",
    "3. txt file refer to h5 file for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, './python')\n",
    "sys.path.append('/local-scratch/xca64/tmp/caffe-master/python/myFunc')\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tempfile\n",
    "from colorConstancy import * \n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_solver(solver, niter, disp_interval, test_interval):\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = (np.zeros(niter), np.zeros(niter))\n",
    "    test_loss = (np.zeros(niter/test_interval)) \n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # run a single SGD step in Caffe\n",
    "        loss[it] = (solver.net.blobs['loss'].data.copy())\n",
    "        acc[it] = 0#(solver.net.blobs['loss_ang'].data.copy())\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = 'loss: %.3f'%loss[it]\n",
    "            print '%3d) %s Angular Erro %.3f' % (it, loss_disp, acc[it])     \n",
    "            #print(solver.net.blobs['fc8_flickr'].data[1], solver.net.blobs['illu'].data[1])\n",
    "        # if it % test_interval == 0:\n",
    "        #     print \"%3d) test loss is %.3f\"% (it ,solver.test_nets[0].blobs['accuracy'].data.copy())\n",
    "        #     test_loss[it//test_interval] = solver.test_nets[0].blobs['accuracy'].data.copy()\n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    name = 'firstTry'\n",
    "    weights = {}\n",
    "    filename = 'weights.%s.caffemodel' % name\n",
    "    \n",
    "    weights[name] = os.path.join(weight_dir, filename)\n",
    "    solver.net.save(weights[name])\n",
    "    \n",
    "    return loss, test_loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Generate all training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname_src = \"/home/xca64/remote/data/shi_funt_filelist.txt\"\n",
    "with open(fname_src) as f:\n",
    "    content_src = f.readlines()\n",
    "fname_illu = \"/home/xca64/remote/data/shi_funt_illu.txt\"\n",
    "with open(fname_illu) as f:\n",
    "    content_illu = f.readlines()\n",
    "    \n",
    "illu = np.zeros([len(content_src),3]) #  len(content_src)\n",
    "src = []\n",
    "for i in range(len(content_src)): #  len(content_src)\n",
    "    illu[i, :] = np.array([float(x) for x in ((content_illu[i])[:-2].split(\"\\t\"))])\n",
    "    src.append(\"/local-scratch/xca64/shi_funt_new\" + content_src[i][:-1] + \" \" + str(i)+\"\\n\")\n",
    "\n",
    "\n",
    "#crossvalidation 1 1 '1' : \n",
    "seprater = 2 * len(content_src)/3  #len(content_src)/3 \n",
    "illu_train = illu[:seprater,:]\n",
    "illu_test = illu[seprater:,:]\n",
    "src_train = src[:seprater]\n",
    "src_test = src[seprater:]\n",
    "\n",
    "#crossvalidation 1 '1' 1 : \n",
    "# seprater1 = len(content_src)/3 #len(content_src)/3 \n",
    "# seprater2 = 2* len(content_src)/3 #len(content_src)/3 \n",
    "# illu_train = np.vstack((illu[:seprater1,:],illu[seprater2:,:] ))\n",
    "# illu_test = illu[seprater1:seprater2,:]\n",
    "# src_train = src[:seprater1] + src[seprater2:]\n",
    "# src_test = src[seprater1:seprater2]\n",
    "\n",
    "#crossvalidation '1' 1 1 : \n",
    "# seprater = len(content_src)/3 #len(content_src)/3 \n",
    "# illu_train = illu[seprater:,:]\n",
    "# illu_test = illu[:seprater,:]\n",
    "# src_train = src[seprater:]\n",
    "# src_test = src[:seprater]\n",
    "\n",
    "# print np.shape(illu_train)\n",
    "# print np.shape(illu_test)\n",
    "# print len(src_train)\n",
    "# print len(src_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"/home/xca64/remote/data/\"\n",
    "fileName = \"test_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "fileName = \"train_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "\n",
    "f = open('/home/xca64/remote/data/train_src.txt', 'w')\n",
    "for i in range(len(src_train)):\n",
    "    f.write(src_train[i])\n",
    "f.close()\n",
    "ft = open('/home/xca64/remote/data/test_src.txt', 'w')\n",
    "for i in range(len(src_test)):\n",
    "    ft.write(src_test[i])\n",
    "ft.close()\n",
    "\n",
    "with h5py.File('/home/xca64/remote/data/test_ill.h5') as h:\n",
    "    h['illu'] = illu_test\n",
    "with h5py.File('/home/xca64/remote/data/train_ill.h5') as h:\n",
    "    h['illu'] = illu_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Training Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Solver\n",
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss: 80.469 Angular Erro 0.000\n",
      " 20) loss: 4.044 Angular Erro 0.000\n",
      " 40) loss: 3.546 Angular Erro 0.000\n",
      " 60) loss: 10.768 Angular Erro 0.000\n",
      " 80) loss: 3.919 Angular Erro 0.000\n",
      "100) loss: 3.720 Angular Erro 0.000\n",
      "120) loss: 10.301 Angular Erro 0.000\n",
      "140) loss: 3.383 Angular Erro 0.000\n",
      "160) loss: 7.007 Angular Erro 0.000\n",
      "180) loss: 8.020 Angular Erro 0.000\n",
      "200) loss: 3.283 Angular Erro 0.000\n",
      "220) loss: 7.383 Angular Erro 0.000\n",
      "240) loss: 4.503 Angular Erro 0.000\n",
      "260) loss: 2.866 Angular Erro 0.000\n",
      "280) loss: 5.322 Angular Erro 0.000\n",
      "300) loss: 2.902 Angular Erro 0.000\n",
      "320) loss: 2.765 Angular Erro 0.000\n",
      "340) loss: 4.207 Angular Erro 0.000\n",
      "360) loss: 2.972 Angular Erro 0.000\n",
      "380) loss: 3.214 Angular Erro 0.000\n",
      "400) loss: 4.772 Angular Erro 0.000\n",
      "420) loss: 2.638 Angular Erro 0.000\n",
      "440) loss: 2.678 Angular Erro 0.000\n",
      "460) loss: 5.682 Angular Erro 0.000\n",
      "480) loss: 2.491 Angular Erro 0.000\n",
      "500) loss: 3.944 Angular Erro 0.000\n",
      "520) loss: 3.915 Angular Erro 0.000\n",
      "540) loss: 2.152 Angular Erro 0.000\n",
      "560) loss: 4.926 Angular Erro 0.000\n",
      "580) loss: 2.845 Angular Erro 0.000\n",
      "600) loss: 2.200 Angular Erro 0.000\n",
      "620) loss: 4.189 Angular Erro 0.000\n",
      "640) loss: 2.575 Angular Erro 0.000\n",
      "660) loss: 2.265 Angular Erro 0.000\n",
      "680) loss: 4.195 Angular Erro 0.000\n",
      "700) loss: 2.308 Angular Erro 0.000\n",
      "720) loss: 2.186 Angular Erro 0.000\n",
      "740) loss: 4.254 Angular Erro 0.000\n",
      "760) loss: 2.283 Angular Erro 0.000\n",
      "780) loss: 2.764 Angular Erro 0.000\n",
      "800) loss: 5.011 Angular Erro 0.000\n",
      "820) loss: 2.075 Angular Erro 0.000\n",
      "840) loss: 4.108 Angular Erro 0.000\n",
      "860) loss: 3.709 Angular Erro 0.000\n",
      "880) loss: 2.009 Angular Erro 0.000\n",
      "900) loss: 4.371 Angular Erro 0.000\n",
      "920) loss: 2.219 Angular Erro 0.000\n",
      "940) loss: 2.040 Angular Erro 0.000\n",
      "960) loss: 3.679 Angular Erro 0.000\n",
      "980) loss: 2.376 Angular Erro 0.000\n",
      "999) loss: 3.493 Angular Erro 0.000\n"
     ]
    }
   ],
   "source": [
    "niters = 1000\n",
    "loss_1, test_loss, acc_1, weights_1 = run_solver(solver, niters,20, 5000)\n",
    "solver.net.save('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')\n",
    "#np.save('/home/xca64/remote/data/shi_funt_crossvalidation_0.npy',loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Validation Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver_validation.prototxt')\n",
    "solver.net.copy_from('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validationIters = 100 #every time forward a batch size image\n",
    "validationSetSize = 161 #number of validation images\n",
    "allAngulareErr = np.array([])\n",
    "allGroundTruth = np.array([0,0,0])\n",
    "allImg = np.zeros([1,3,227,227])\n",
    "for it in range(validationIters):\n",
    "    solver.net.forward()\n",
    "    estimatedIllu = solver.net.blobs['fc8_flickr'].data.copy()  #batch size illumination estimation result\n",
    "    groundtruethIllu = solver.net.blobs['illu'].data.copy()  #batch size illumination estimation result\n",
    "    #print solver.net.blobs['label'].data.copy() \n",
    "    #allGroundTruth = np.vstack((allGroundTruth, estimatedIllu))\n",
    "    #allImg = np.vstack((allImg, solver.net.blobs['data'].data.copy() ))\n",
    "    allAngulareErr = np.hstack((allAngulareErr, np.squeeze( multiangle(estimatedIllu, groundtruethIllu))))\n",
    "    #print np.shape(allAngulareErr)\n",
    "    #allAngulareErr = np.vstack((allAngulareErr, multiangle(estimatedIllu, groundtruethIllu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allAngulareErr)):\n",
    "    for j in range(len(allAngulareErr)):\n",
    "        if allAngulareErr[i] == allAngulareErr[j] and i != j:\n",
    "            print i\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6823740265289731, 3.1542084660251568, 3.2734794171068877, 0.052339155975479217, 8.6237436132712553]\n"
     ]
    }
   ],
   "source": [
    "final_result =[];\n",
    "final_result.append(np.mean(allAngulareErr))\n",
    "final_result.append(np.median(allAngulareErr))\n",
    "final_result.append((np.percentile(allAngulareErr,25)+ np.percentile(allAngulareErr,75) + 2 *np.median(allAngulareErr))/4)\n",
    "final_result.append(np.amin(allAngulareErr))\n",
    "final_result.append(np.percentile(allAngulareErr,95))\n",
    "print final_result\n",
    "fileName = \"final_result.txt\"\n",
    "rmCommand = \"rm -rf /home/xca64/remote/data/\" + fileName\n",
    "#os.system(rmCommand)\n",
    "f = open('/home/xca64/remote/data/final_result.txt', 'a')\n",
    "f.write(\"result for shi_funt crossvalidation 1 1 '1' :\\n\")\n",
    "f.write(str(final_result))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print np.mean(allAngulareErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = solver.net.blobs['data'].data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allImg = np.zeros([1,3,227,227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = allImg[162,...]\n",
    "plt.imshow(deprocess_net_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
