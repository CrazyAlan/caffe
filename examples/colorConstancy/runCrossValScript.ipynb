{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the trainning and validation set file \n",
    "1. list txt for training and validation\n",
    "2. h5 file for training and validation\n",
    "3. txt file refer to h5 file for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, './python')\n",
    "sys.path.append('/local-scratch/xca64/tmp/caffe-master/python/myFunc')\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tempfile\n",
    "from colorConstancy import * \n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_solver(solver, niter, disp_interval, test_interval):\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = (np.zeros(niter), np.zeros(niter))\n",
    "    test_loss = (np.zeros(niter/test_interval)) \n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # run a single SGD step in Caffe\n",
    "        loss[it] = (solver.net.blobs['loss'].data.copy())\n",
    "        acc[it] = 0#(solver.net.blobs['loss_ang'].data.copy())\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = 'loss: %.3f'%loss[it]\n",
    "            print '%3d) %s Angular Erro %.3f' % (it, loss_disp, acc[it])     \n",
    "            #print(solver.net.blobs['fc8_flickr'].data[1], solver.net.blobs['illu'].data[1])\n",
    "        # if it % test_interval == 0:\n",
    "        #     print \"%3d) test loss is %.3f\"% (it ,solver.test_nets[0].blobs['accuracy'].data.copy())\n",
    "        #     test_loss[it//test_interval] = solver.test_nets[0].blobs['accuracy'].data.copy()\n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    name = 'firstTry'\n",
    "    weights = {}\n",
    "    filename = 'weights.%s.caffemodel' % name\n",
    "    \n",
    "    weights[name] = os.path.join(weight_dir, filename)\n",
    "    solver.net.save(weights[name])\n",
    "    \n",
    "    return loss, test_loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Generate all training and validation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Training Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Solver\n",
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss: 122.712 Angular Erro 0.000\n",
      " 20) loss: 0.639 Angular Erro 0.000\n",
      " 40) loss: 0.450 Angular Erro 0.000\n",
      " 60) loss: 16.742 Angular Erro 0.000\n",
      " 80) loss: 13.246 Angular Erro 0.000\n",
      "100) loss: 22.189 Angular Erro 0.000\n",
      "120) loss: 4.481 Angular Erro 0.000\n",
      "140) loss: 4.709 Angular Erro 0.000\n",
      "160) loss: 11.611 Angular Erro 0.000\n",
      "180) loss: 4.651 Angular Erro 0.000\n",
      "200) loss: 3.790 Angular Erro 0.000\n",
      "220) loss: 0.738 Angular Erro 0.000\n",
      "240) loss: 21.765 Angular Erro 0.000\n",
      "260) loss: 8.337 Angular Erro 0.000\n",
      "280) loss: 23.134 Angular Erro 0.000\n",
      "300) loss: 4.599 Angular Erro 0.000\n",
      "320) loss: 4.456 Angular Erro 0.000\n",
      "340) loss: 4.332 Angular Erro 0.000\n",
      "360) loss: 3.330 Angular Erro 0.000\n",
      "380) loss: 3.678 Angular Erro 0.000\n",
      "400) loss: 6.739 Angular Erro 0.000\n",
      "420) loss: 2.140 Angular Erro 0.000\n",
      "440) loss: 4.341 Angular Erro 0.000\n",
      "460) loss: 12.317 Angular Erro 0.000\n",
      "480) loss: 7.535 Angular Erro 0.000\n",
      "500) loss: 3.946 Angular Erro 0.000\n",
      "520) loss: 6.921 Angular Erro 0.000\n",
      "540) loss: 2.827 Angular Erro 0.000\n",
      "560) loss: 1.472 Angular Erro 0.000\n",
      "580) loss: 4.541 Angular Erro 0.000\n",
      "600) loss: 3.408 Angular Erro 0.000\n",
      "620) loss: 5.783 Angular Erro 0.000\n",
      "640) loss: 4.588 Angular Erro 0.000\n",
      "660) loss: 3.501 Angular Erro 0.000\n",
      "680) loss: 6.433 Angular Erro 0.000\n",
      "700) loss: 7.658 Angular Erro 0.000\n",
      "720) loss: 4.423 Angular Erro 0.000\n",
      "740) loss: 2.779 Angular Erro 0.000\n",
      "760) loss: 1.053 Angular Erro 0.000\n",
      "780) loss: 8.506 Angular Erro 0.000\n",
      "800) loss: 5.857 Angular Erro 0.000\n",
      "820) loss: 6.218 Angular Erro 0.000\n",
      "840) loss: 2.577 Angular Erro 0.000\n",
      "860) loss: 8.026 Angular Erro 0.000\n",
      "880) loss: 3.892 Angular Erro 0.000\n",
      "900) loss: 4.618 Angular Erro 0.000\n",
      "920) loss: 2.743 Angular Erro 0.000\n",
      "940) loss: 1.406 Angular Erro 0.000\n",
      "960) loss: 7.786 Angular Erro 0.000\n",
      "980) loss: 2.392 Angular Erro 0.000\n",
      "999) loss: 4.913 Angular Erro 0.000\n"
     ]
    }
   ],
   "source": [
    "niters = 1000\n",
    "loss_1, test_loss, acc_1, weights_1 = run_solver(solver, niters,20, 5000)\n",
    "solver.net.save('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Validation Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver_validation.prototxt')\n",
    "solver.net.copy_from('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fc8_flickr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-06672d59f5d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationIters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mestimatedIllu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fc8_flickr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#batch size illumination estimation result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mgroundtruethIllu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'illu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#batch size illumination estimation result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print solver.net.blobs['label'].data.copy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fc8_flickr'"
     ]
    }
   ],
   "source": [
    "validationIters = 15 #every time forward a batch size image\n",
    "validationSetSize = 161 #number of validation images\n",
    "allAngulareErr = np.array([])\n",
    "allGroundTruth = np.array([0,0,0])\n",
    "allImg = np.zeros([1,3,227,227])\n",
    "for it in range(validationIters):\n",
    "    solver.net.forward()\n",
    "    estimatedIllu = solver.net.blobs['fc8_flickr'].data.copy()  #batch size illumination estimation result\n",
    "    groundtruethIllu = solver.net.blobs['illu'].data.copy()  #batch size illumination estimation result\n",
    "    #print solver.net.blobs['label'].data.copy() \n",
    "    #allGroundTruth = np.vstack((allGroundTruth, estimatedIllu))\n",
    "    #allImg = np.vstack((allImg, solver.net.blobs['data'].data.copy() ))\n",
    "    allAngulareErr = np.hstack((allAngulareErr, np.squeeze( multiangle(estimatedIllu, groundtruethIllu))))\n",
    "    print np.shape(allAngulareErr)\n",
    "    #allAngulareErr = np.vstack((allAngulareErr, multiangle(estimatedIllu, groundtruethIllu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allAngulareErr)):\n",
    "    for j in range(len(allAngulareErr)):\n",
    "        if allAngulareErr[i] == allAngulareErr[j] and i != j:\n",
    "            print i\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(allAngulareErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = solver.net.blobs['data'].data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allImg = np.zeros([1,3,227,227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = allImg[162,...]\n",
    "plt.imshow(deprocess_net_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
