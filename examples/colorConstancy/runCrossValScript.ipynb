{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the trainning and validation set file \n",
    "1. list txt for training and validation\n",
    "2. h5 file for training and validation\n",
    "3. txt file refer to h5 file for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, './python')\n",
    "sys.path.append('/local-scratch/xca64/tmp/caffe-master/python/myFunc')\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tempfile\n",
    "from colorConstancy import * \n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_solver(solver, niter, disp_interval, test_interval):\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = (np.zeros(niter), np.zeros(niter))\n",
    "    test_loss = (np.zeros(niter/test_interval)) \n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # run a single SGD step in Caffe\n",
    "        loss[it] = (solver.net.blobs['loss'].data.copy())\n",
    "        acc[it] = 0#(solver.net.blobs['loss_ang'].data.copy())\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = 'loss: %.3f'%loss[it]\n",
    "            print '%3d) %s Angular Erro %.3f' % (it, loss_disp, acc[it])     \n",
    "            #print(solver.net.blobs['fc8_flickr'].data[1], solver.net.blobs['illu'].data[1])\n",
    "        # if it % test_interval == 0:\n",
    "        #     print \"%3d) test loss is %.3f\"% (it ,solver.test_nets[0].blobs['accuracy'].data.copy())\n",
    "        #     test_loss[it//test_interval] = solver.test_nets[0].blobs['accuracy'].data.copy()\n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    name = 'firstTry'\n",
    "    weights = {}\n",
    "    filename = 'weights.%s.caffemodel' % name\n",
    "    \n",
    "    weights[name] = os.path.join(weight_dir, filename)\n",
    "    solver.net.save(weights[name])\n",
    "    \n",
    "    return loss, test_loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Generate all training and validation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Training Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Solver\n",
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "niters = 100\n",
    "loss_1, test_loss, acc_1, weights_1 = run_solver(solver, niters,20, 5000)\n",
    "solver.net.save('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Validation Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver_validation.prototxt')\n",
    "solver.net.copy_from('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validationIters = 14 #every time forward a batch size image\n",
    "validationSetSize = 161 #number of validation images\n",
    "allAngulareErr = np.array([])\n",
    "allGroundTruth = np.array([0,0,0])\n",
    "allImg = np.zeros([1,3,227,227])\n",
    "for it in range(validationIters):\n",
    "    solver.net.forward()\n",
    "    estimatedIllu = solver.net.blobs['fc8_flickr'].data.copy()  #batch size illumination estimation result\n",
    "    groundtruethIllu = solver.net.blobs['illu'].data.copy()  #batch size illumination estimation result\n",
    "    #print solver.net.blobs['label'].data.copy() \n",
    "    #allGroundTruth = np.vstack((allGroundTruth, estimatedIllu))\n",
    "    #allImg = np.vstack((allImg, solver.net.blobs['data'].data.copy() ))\n",
    "    allAngulareErr = np.hstack((allAngulareErr, np.squeeze( multiangle(estimatedIllu, groundtruethIllu))))\n",
    "    print np.shape(allAngulareErr)\n",
    "    #allAngulareErr = np.vstack((allAngulareErr, multiangle(estimatedIllu, groundtruethIllu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allAngulareErr)):\n",
    "    for j in range(len(allAngulareErr)):\n",
    "        if allAngulareErr[i] == allAngulareErr[j] and i != j:\n",
    "            print i\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(allAngulareErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = solver.net.blobs['data'].data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allImg = np.zeros([1,3,227,227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = allImg[162,...]\n",
    "plt.imshow(deprocess_net_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
