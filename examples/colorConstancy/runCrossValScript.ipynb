{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the trainning and validation set file \n",
    "1. list txt for training and validation\n",
    "2. h5 file for training and validation\n",
    "3. txt file refer to h5 file for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "#from scipy import stats\n",
    "#from random import shuffle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, './python')\n",
    "sys.path.append('/local-scratch/xca64/tmp/caffe-master/python/myFunc')\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tempfile\n",
    "from colorConstancy import * \n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_solver(solver, niter, disp_interval, test_interval):\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = (np.zeros(niter), np.zeros(niter))\n",
    "    test_loss = (np.zeros(niter/test_interval)) \n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # run a single SGD step in Caffe\n",
    "        loss[it] = (solver.net.blobs['loss'].data.copy())\n",
    "        acc[it] = 0#(solver.net.blobs['loss_ang'].data.copy())\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = 'loss: %.3f'%loss[it]\n",
    "            print '%3d) %s Angular Erro %.3f' % (it, loss_disp, acc[it])     \n",
    "            #print(solver.net.blobs['fc8_flickr'].data[1], solver.net.blobs['illu'].data[1])\n",
    "        # if it % test_interval == 0:\n",
    "        #     print \"%3d) test loss is %.3f\"% (it ,solver.test_nets[0].blobs['accuracy'].data.copy())\n",
    "        #     test_loss[it//test_interval] = solver.test_nets[0].blobs['accuracy'].data.copy()\n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    name = 'firstTry'\n",
    "    weights = {}\n",
    "    filename = 'weights.%s.caffemodel' % name\n",
    "    \n",
    "    weights[name] = os.path.join(weight_dir, filename)\n",
    "    solver.net.save(weights[name])\n",
    "    \n",
    "    return loss, test_loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Generate all training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"/home/xca64/remote/GitHub/colorP/dataSet/geler/Gehler_Extras/Illuminants.txt\"\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "illu = np.zeros([len(content)/3,3]) #  len(content_src)\n",
    "src = []\n",
    "for i in range(len(content)/3): #  len(content_src)\n",
    "    illu[i, :] = np.array([float(x) for x in ((content[i*3+1][:-3]).split(','))])\n",
    "    src.append(\"/local-scratch/xca64/geler/source/\" + content[i*3][:-2] + \" \" + str(i)+\"\\n\")\n",
    "\n",
    "\n",
    "#crossvalidation 1 1 '1' : \n",
    "# seprater = 2* len(content)/9 #len(content_src)/3 \n",
    "# illu_train = illu[:seprater,:]\n",
    "# illu_test = illu[seprater:,:]\n",
    "# src_train = src[:seprater]\n",
    "# src_test = src[seprater:]\n",
    "\n",
    "#crossvalidation 1 '1' 1 : \n",
    "# seprater1 = len(content)/9 #len(content_src)/3 \n",
    "# seprater2 = 2* len(content)/9 #len(content_src)/3 \n",
    "# illu_train = np.vstack((illu[:seprater1,:],illu[seprater2:,:] ))\n",
    "# illu_test = illu[seprater1:seprater2,:]\n",
    "# src_train = src[:seprater1] + src[seprater2:]\n",
    "# src_test = src[seprater1:seprater2]\n",
    "\n",
    "#crossvalidation '1' 1 1 : \n",
    "seprater = len(content)/9 #len(content_src)/3 \n",
    "illu_train = illu[seprater:,:]\n",
    "illu_test = illu[:seprater,:]\n",
    "src_train = src[seprater:]\n",
    "src_test = src[:seprater]\n",
    "\n",
    "# print np.shape(illu_train)\n",
    "# print np.shape(illu_test)\n",
    "# print len(src_train)\n",
    "# print len(src_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"/home/xca64/remote/data/\"\n",
    "fileName = \"test_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "fileName = \"train_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "\n",
    "f = open('/home/xca64/remote/data/train_src.txt', 'w')\n",
    "for i in range(len(src_train)):\n",
    "    f.write(src_train[i])\n",
    "f.close()\n",
    "ft = open('/home/xca64/remote/data/test_src.txt', 'w')\n",
    "for i in range(len(src_test)):\n",
    "    ft.write(src_test[i])\n",
    "ft.close()\n",
    "\n",
    "with h5py.File('/home/xca64/remote/data/test_ill.h5') as h:\n",
    "    h['illu'] = illu_test\n",
    "with h5py.File('/home/xca64/remote/data/train_ill.h5') as h:\n",
    "    h['illu'] = illu_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Training Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training Solver\n",
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss: 87.560 Angular Erro 0.000\n",
      " 20) loss: 9.025 Angular Erro 0.000\n",
      " 40) loss: 15.530 Angular Erro 0.000\n",
      " 60) loss: 13.662 Angular Erro 0.000\n",
      " 80) loss: 5.910 Angular Erro 0.000\n",
      "100) loss: 4.173 Angular Erro 0.000\n",
      "120) loss: 3.487 Angular Erro 0.000\n",
      "140) loss: 4.414 Angular Erro 0.000\n",
      "160) loss: 4.418 Angular Erro 0.000\n",
      "180) loss: 3.808 Angular Erro 0.000\n",
      "200) loss: 2.781 Angular Erro 0.000\n",
      "220) loss: 3.649 Angular Erro 0.000\n",
      "240) loss: 4.272 Angular Erro 0.000\n",
      "260) loss: 3.105 Angular Erro 0.000\n",
      "280) loss: 2.992 Angular Erro 0.000\n",
      "300) loss: 2.368 Angular Erro 0.000\n",
      "320) loss: 2.186 Angular Erro 0.000\n",
      "340) loss: 3.256 Angular Erro 0.000\n",
      "360) loss: 2.826 Angular Erro 0.000\n",
      "380) loss: 2.765 Angular Erro 0.000\n",
      "400) loss: 2.289 Angular Erro 0.000\n",
      "420) loss: 3.411 Angular Erro 0.000\n",
      "440) loss: 2.834 Angular Erro 0.000\n",
      "460) loss: 2.292 Angular Erro 0.000\n",
      "480) loss: 1.859 Angular Erro 0.000\n",
      "500) loss: 1.542 Angular Erro 0.000\n",
      "520) loss: 2.220 Angular Erro 0.000\n",
      "540) loss: 3.192 Angular Erro 0.000\n",
      "560) loss: 2.829 Angular Erro 0.000\n",
      "580) loss: 1.693 Angular Erro 0.000\n",
      "600) loss: 2.610 Angular Erro 0.000\n",
      "620) loss: 2.707 Angular Erro 0.000\n",
      "640) loss: 2.338 Angular Erro 0.000\n",
      "660) loss: 1.919 Angular Erro 0.000\n",
      "680) loss: 1.613 Angular Erro 0.000\n",
      "700) loss: 1.857 Angular Erro 0.000\n",
      "720) loss: 2.689 Angular Erro 0.000\n",
      "740) loss: 2.929 Angular Erro 0.000\n",
      "760) loss: 2.271 Angular Erro 0.000\n",
      "780) loss: 2.200 Angular Erro 0.000\n",
      "800) loss: 2.738 Angular Erro 0.000\n",
      "820) loss: 2.446 Angular Erro 0.000\n",
      "840) loss: 2.232 Angular Erro 0.000\n",
      "860) loss: 1.595 Angular Erro 0.000\n",
      "880) loss: 1.314 Angular Erro 0.000\n",
      "900) loss: 1.868 Angular Erro 0.000\n",
      "920) loss: 2.614 Angular Erro 0.000\n",
      "940) loss: 2.484 Angular Erro 0.000\n",
      "960) loss: 1.930 Angular Erro 0.000\n",
      "980) loss: 2.569 Angular Erro 0.000\n",
      "1000) loss: 2.090 Angular Erro 0.000\n",
      "1020) loss: 1.796 Angular Erro 0.000\n",
      "1040) loss: 1.706 Angular Erro 0.000\n",
      "1060) loss: 1.516 Angular Erro 0.000\n",
      "1080) loss: 1.599 Angular Erro 0.000\n",
      "1100) loss: 2.738 Angular Erro 0.000\n",
      "1120) loss: 2.627 Angular Erro 0.000\n",
      "1140) loss: 1.966 Angular Erro 0.000\n",
      "1160) loss: 1.894 Angular Erro 0.000\n",
      "1180) loss: 2.237 Angular Erro 0.000\n",
      "1200) loss: 1.977 Angular Erro 0.000\n",
      "1220) loss: 2.002 Angular Erro 0.000\n",
      "1240) loss: 1.647 Angular Erro 0.000\n",
      "1260) loss: 1.312 Angular Erro 0.000\n",
      "1280) loss: 2.316 Angular Erro 0.000\n",
      "1300) loss: 2.291 Angular Erro 0.000\n",
      "1320) loss: 2.410 Angular Erro 0.000\n",
      "1340) loss: 1.748 Angular Erro 0.000\n",
      "1360) loss: 2.085 Angular Erro 0.000\n",
      "1380) loss: 2.035 Angular Erro 0.000\n",
      "1400) loss: 1.874 Angular Erro 0.000\n",
      "1420) loss: 1.841 Angular Erro 0.000\n",
      "1440) loss: 1.526 Angular Erro 0.000\n",
      "1460) loss: 1.327 Angular Erro 0.000\n",
      "1480) loss: 2.116 Angular Erro 0.000\n",
      "1500) loss: 2.338 Angular Erro 0.000\n",
      "1520) loss: 1.669 Angular Erro 0.000\n",
      "1540) loss: 2.178 Angular Erro 0.000\n",
      "1560) loss: 2.627 Angular Erro 0.000\n",
      "1580) loss: 2.128 Angular Erro 0.000\n",
      "1600) loss: 1.740 Angular Erro 0.000\n",
      "1620) loss: 1.660 Angular Erro 0.000\n",
      "1640) loss: 1.390 Angular Erro 0.000\n",
      "1660) loss: 1.970 Angular Erro 0.000\n",
      "1680) loss: 2.494 Angular Erro 0.000\n",
      "1700) loss: 2.315 Angular Erro 0.000\n",
      "1720) loss: 1.395 Angular Erro 0.000\n",
      "1740) loss: 1.992 Angular Erro 0.000\n",
      "1760) loss: 1.959 Angular Erro 0.000\n",
      "1780) loss: 2.136 Angular Erro 0.000\n",
      "1800) loss: 1.786 Angular Erro 0.000\n",
      "1820) loss: 1.480 Angular Erro 0.000\n",
      "1840) loss: 1.437 Angular Erro 0.000\n",
      "1860) loss: 2.477 Angular Erro 0.000\n",
      "1880) loss: 1.973 Angular Erro 0.000\n",
      "1900) loss: 1.980 Angular Erro 0.000\n",
      "1920) loss: 1.907 Angular Erro 0.000\n",
      "1940) loss: 2.152 Angular Erro 0.000\n",
      "1960) loss: 1.620 Angular Erro 0.000\n",
      "1980) loss: 1.553 Angular Erro 0.000\n",
      "2000) loss: 1.415 Angular Erro 0.000\n",
      "2020) loss: 1.310 Angular Erro 0.000\n",
      "2040) loss: 2.148 Angular Erro 0.000\n",
      "2060) loss: 2.606 Angular Erro 0.000\n",
      "2080) loss: 2.206 Angular Erro 0.000\n",
      "2100) loss: 2.163 Angular Erro 0.000\n",
      "2120) loss: 2.165 Angular Erro 0.000\n",
      "2140) loss: 1.928 Angular Erro 0.000\n",
      "2160) loss: 2.030 Angular Erro 0.000\n",
      "2180) loss: 1.593 Angular Erro 0.000\n",
      "2200) loss: 1.386 Angular Erro 0.000\n",
      "2220) loss: 1.538 Angular Erro 0.000\n",
      "2240) loss: 2.179 Angular Erro 0.000\n",
      "2260) loss: 2.178 Angular Erro 0.000\n",
      "2280) loss: 1.664 Angular Erro 0.000\n",
      "2300) loss: 2.080 Angular Erro 0.000\n",
      "2320) loss: 1.960 Angular Erro 0.000\n",
      "2340) loss: 1.865 Angular Erro 0.000\n",
      "2360) loss: 1.600 Angular Erro 0.000\n",
      "2380) loss: 1.731 Angular Erro 0.000\n",
      "2400) loss: 1.235 Angular Erro 0.000\n",
      "2420) loss: 2.080 Angular Erro 0.000\n",
      "2440) loss: 2.265 Angular Erro 0.000\n",
      "2460) loss: 2.097 Angular Erro 0.000\n",
      "2480) loss: 1.810 Angular Erro 0.000\n",
      "2500) loss: 2.365 Angular Erro 0.000\n",
      "2520) loss: 2.171 Angular Erro 0.000\n",
      "2540) loss: 1.971 Angular Erro 0.000\n",
      "2560) loss: 1.730 Angular Erro 0.000\n",
      "2580) loss: 1.213 Angular Erro 0.000\n",
      "2600) loss: 1.512 Angular Erro 0.000\n",
      "2620) loss: 2.318 Angular Erro 0.000\n",
      "2640) loss: 2.287 Angular Erro 0.000\n",
      "2660) loss: 1.618 Angular Erro 0.000\n",
      "2680) loss: 2.096 Angular Erro 0.000\n",
      "2700) loss: 2.066 Angular Erro 0.000\n",
      "2720) loss: 1.857 Angular Erro 0.000\n",
      "2740) loss: 1.526 Angular Erro 0.000\n",
      "2760) loss: 1.569 Angular Erro 0.000\n",
      "2780) loss: 1.189 Angular Erro 0.000\n",
      "2800) loss: 2.295 Angular Erro 0.000\n",
      "2820) loss: 2.101 Angular Erro 0.000\n",
      "2840) loss: 1.943 Angular Erro 0.000\n",
      "2860) loss: 1.616 Angular Erro 0.000\n",
      "2880) loss: 2.251 Angular Erro 0.000\n",
      "2900) loss: 1.896 Angular Erro 0.000\n",
      "2920) loss: 1.711 Angular Erro 0.000\n",
      "2940) loss: 1.638 Angular Erro 0.000\n",
      "2960) loss: 1.427 Angular Erro 0.000\n",
      "2980) loss: 1.493 Angular Erro 0.000\n",
      "2999) loss: 1.170 Angular Erro 0.000\n"
     ]
    }
   ],
   "source": [
    "niters = 3000\n",
    "loss_1, test_loss, acc_1, weights_1 = run_solver(solver, niters,20, 5000)\n",
    "solver.net.save('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')\n",
    "np.save('/home/xca64/remote/data/geler_crossvalidation_A2_0.npy', loss_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Validation Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver_validation.prototxt')\n",
    "solver.net.copy_from('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validationIters = 100 # 500 #every time forward a batch size image\n",
    "validationSetSize = 161 #number of validation images\n",
    "allAngulareErr = np.array([])\n",
    "allGroundTruth = np.array([0,0,0])\n",
    "allImg = np.zeros([1,3,227,227])\n",
    "for it in range(validationIters):\n",
    "    solver.net.forward()\n",
    "    estimatedIllu = solver.net.blobs['fc9'].data.copy()  #batch size illumination estimation result\n",
    "    groundtruethIllu = solver.net.blobs['illu'].data.copy()  #batch size illumination estimation result\n",
    "    #print solver.net.blobs['label'].data.copy() \n",
    "    #allGroundTruth = np.vstack((allGroundTruth, estimatedIllu))\n",
    "    #allImg = np.vstack((allImg, solver.net.blobs['data'].data.copy() ))\n",
    "    allAngulareErr = np.hstack((allAngulareErr, np.squeeze( multiangle(estimatedIllu, groundtruethIllu))))\n",
    "    #print np.shape(allAngulareErr)\n",
    "    #allAngulareErr = np.vstack((allAngulareErr, multiangle(estimatedIllu, groundtruethIllu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allAngulareErr)):\n",
    "    for j in range(len(allAngulareErr)):\n",
    "        if allAngulareErr[i] == allAngulareErr[j] and i != j:\n",
    "            print i\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result =[];\n",
    "final_result.append(np.mean(allAngulareErr))\n",
    "final_result.append(np.median(allAngulareErr))\n",
    "final_result.append((np.percentile(allAngulareErr,25)+ np.percentile(allAngulareErr,75) + 2 *np.median(allAngulareErr))/4)\n",
    "final_result.append(np.amin(allAngulareErr))\n",
    "final_result.append(np.percentile(allAngulareErr,95))\n",
    "#print final_result\n",
    "fileName = \"final_result.txt\"\n",
    "rmCommand = \"rm -rf /home/xca64/remote/data/\" + fileName\n",
    "#os.system(rmCommand)\n",
    "f = open('/home/xca64/remote/data/final_result.txt', 'a')\n",
    "f.write(\"result for geler crossvalidation A2 1 '1' 1 :\\n\")\n",
    "f.write(str(final_result))\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(allAngulareErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = solver.net.blobs['data'].data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allImg = np.zeros([1,3,227,227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = allImg[162,...]\n",
    "plt.imshow(deprocess_net_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
