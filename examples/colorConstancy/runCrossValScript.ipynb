{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the trainning and validation set file \n",
    "1. list txt for training and validation\n",
    "2. h5 file for training and validation\n",
    "3. txt file refer to h5 file for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "#from scipy import stats\n",
    "#from random import shuffle\n",
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, './python')\n",
    "sys.path.append('/local-scratch/xca64/tmp/caffe-master/python/myFunc')\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tempfile\n",
    "from colorConstancy import * \n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_solver(solver, niter, disp_interval, test_interval):\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = (np.zeros(niter), np.zeros(niter))\n",
    "    test_loss = (np.zeros(niter/test_interval)) \n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # run a single SGD step in Caffe\n",
    "        loss[it] = (solver.net.blobs['loss'].data.copy())\n",
    "        acc[it] = 0#(solver.net.blobs['loss_ang'].data.copy())\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = 'loss: %.3f'%loss[it]\n",
    "            print '%3d) %s Angular Erro %.3f' % (it, loss_disp, acc[it])     \n",
    "            #print(solver.net.blobs['fc8_flickr'].data[1], solver.net.blobs['illu'].data[1])\n",
    "        # if it % test_interval == 0:\n",
    "        #     print \"%3d) test loss is %.3f\"% (it ,solver.test_nets[0].blobs['accuracy'].data.copy())\n",
    "        #     test_loss[it//test_interval] = solver.test_nets[0].blobs['accuracy'].data.copy()\n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    name = 'firstTry'\n",
    "    weights = {}\n",
    "    filename = 'weights.%s.caffemodel' % name\n",
    "    \n",
    "    weights[name] = os.path.join(weight_dir, filename)\n",
    "    solver.net.save(weights[name])\n",
    "    \n",
    "    return loss, test_loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Generate all training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"/home/xca64/remote/GitHub/colorP/dataSet/geler/Gehler_Extras/Illuminants.txt\"\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "illu = np.zeros([len(content)/3,3]) #  len(content_src)\n",
    "src = []\n",
    "for i in range(len(content)/3): #  len(content_src)\n",
    "    illu[i, :] = np.array([float(x) for x in ((content[i*3+1][:-3]).split(','))])\n",
    "    src.append(\"/local-scratch/xca64/geler/source/\" + content[i*3][:-2] + \" \" + str(i)+\"\\n\")\n",
    "\n",
    "\n",
    "#crossvalidation 1 1 '1' : \n",
    "# seprater = 2* len(content)/9 #len(content_src)/3 \n",
    "# illu_train = illu[:seprater,:]\n",
    "# illu_test = illu[seprater:,:]\n",
    "# src_train = src[:seprater]\n",
    "# src_test = src[seprater:]\n",
    "\n",
    "#crossvalidation 1 '1' 1 : \n",
    "seprater1 = len(content)/9 #len(content_src)/3 \n",
    "seprater2 = 2* len(content)/9 #len(content_src)/3 \n",
    "illu_train = np.vstack((illu[:seprater1,:],illu[seprater2:,:] ))\n",
    "illu_test = illu[seprater1:seprater2,:]\n",
    "src_train = src[:seprater1] + src[seprater2:]\n",
    "src_test = src[seprater1:seprater2]\n",
    "\n",
    "#crossvalidation '1' 1 1 : \n",
    "# seprater = len(content)/9 #len(content_src)/3 \n",
    "# illu_train = illu[seprater:,:]\n",
    "# illu_test = illu[:seprater,:]\n",
    "# src_train = src[seprater:]\n",
    "# src_test = src[:seprater]\n",
    "\n",
    "# print np.shape(illu_train)\n",
    "# print np.shape(illu_test)\n",
    "# print len(src_train)\n",
    "# print len(src_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"/home/xca64/remote/data/\"\n",
    "fileName = \"test_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "fileName = \"train_ill.h5\"\n",
    "rmCommand = \"rm -rf \" +  dataPath + fileName \n",
    "os.system(rmCommand)\n",
    "\n",
    "f = open('/home/xca64/remote/data/train_src.txt', 'w')\n",
    "for i in range(len(src_train)):\n",
    "    f.write(src_train[i])\n",
    "f.close()\n",
    "ft = open('/home/xca64/remote/data/test_src.txt', 'w')\n",
    "for i in range(len(src_test)):\n",
    "    ft.write(src_test[i])\n",
    "ft.close()\n",
    "\n",
    "with h5py.File('/home/xca64/remote/data/test_ill.h5') as h:\n",
    "    h['illu'] = illu_test\n",
    "with h5py.File('/home/xca64/remote/data/train_ill.h5') as h:\n",
    "    h['illu'] = illu_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Training Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training Solver\n",
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss: 111.012 Angular Erro 0.000\n",
      " 20) loss: 5.711 Angular Erro 0.000\n",
      " 40) loss: 3.942 Angular Erro 0.000\n",
      " 60) loss: 5.191 Angular Erro 0.000\n",
      " 80) loss: 5.255 Angular Erro 0.000\n",
      "100) loss: 4.310 Angular Erro 0.000\n",
      "120) loss: 5.565 Angular Erro 0.000\n",
      "140) loss: 9.569 Angular Erro 0.000\n",
      "160) loss: 7.118 Angular Erro 0.000\n",
      "180) loss: 3.027 Angular Erro 0.000\n",
      "200) loss: 2.894 Angular Erro 0.000\n",
      "220) loss: 3.565 Angular Erro 0.000\n",
      "240) loss: 4.528 Angular Erro 0.000\n",
      "260) loss: 2.814 Angular Erro 0.000\n",
      "280) loss: 3.700 Angular Erro 0.000\n",
      "300) loss: 7.047 Angular Erro 0.000\n",
      "320) loss: 8.490 Angular Erro 0.000\n",
      "340) loss: 5.053 Angular Erro 0.000\n",
      "360) loss: 2.650 Angular Erro 0.000\n",
      "380) loss: 2.968 Angular Erro 0.000\n",
      "400) loss: 3.135 Angular Erro 0.000\n",
      "420) loss: 3.625 Angular Erro 0.000\n",
      "440) loss: 2.762 Angular Erro 0.000\n",
      "460) loss: 2.852 Angular Erro 0.000\n",
      "480) loss: 6.083 Angular Erro 0.000\n",
      "500) loss: 4.350 Angular Erro 0.000\n",
      "520) loss: 2.654 Angular Erro 0.000\n",
      "540) loss: 2.888 Angular Erro 0.000\n",
      "560) loss: 2.730 Angular Erro 0.000\n",
      "580) loss: 3.362 Angular Erro 0.000\n",
      "600) loss: 3.124 Angular Erro 0.000\n",
      "620) loss: 2.391 Angular Erro 0.000\n",
      "640) loss: 3.388 Angular Erro 0.000\n",
      "660) loss: 4.879 Angular Erro 0.000\n",
      "680) loss: 3.791 Angular Erro 0.000\n",
      "700) loss: 2.274 Angular Erro 0.000\n",
      "720) loss: 2.732 Angular Erro 0.000\n",
      "740) loss: 2.781 Angular Erro 0.000\n",
      "760) loss: 2.944 Angular Erro 0.000\n",
      "780) loss: 2.619 Angular Erro 0.000\n",
      "800) loss: 2.022 Angular Erro 0.000\n",
      "820) loss: 3.663 Angular Erro 0.000\n",
      "840) loss: 4.612 Angular Erro 0.000\n",
      "860) loss: 2.689 Angular Erro 0.000\n",
      "880) loss: 2.366 Angular Erro 0.000\n",
      "900) loss: 2.643 Angular Erro 0.000\n",
      "920) loss: 2.593 Angular Erro 0.000\n",
      "940) loss: 2.639 Angular Erro 0.000\n",
      "960) loss: 2.349 Angular Erro 0.000\n",
      "980) loss: 2.083 Angular Erro 0.000\n",
      "999) loss: 2.304 Angular Erro 0.000\n"
     ]
    }
   ],
   "source": [
    "niters = 1000\n",
    "loss_1, test_loss, acc_1, weights_1 = run_solver(solver, niters,20, 5000)\n",
    "solver.net.save('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')\n",
    "np.save('/home/xca64/remote/data/geler_crossvalidation_1.npy', loss_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define Validation Solver and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('models/color_constancy/gehler_482_solver_validation.prototxt')\n",
    "solver.net.copy_from('models/color_constancy/result/gehler_482_3000_iters_cross_validation.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validationIters = 100 # 500 #every time forward a batch size image\n",
    "validationSetSize = 161 #number of validation images\n",
    "allAngulareErr = np.array([])\n",
    "allGroundTruth = np.array([0,0,0])\n",
    "allImg = np.zeros([1,3,227,227])\n",
    "for it in range(validationIters):\n",
    "    solver.net.forward()\n",
    "    estimatedIllu = solver.net.blobs['fc8_flickr'].data.copy()  #batch size illumination estimation result\n",
    "    groundtruethIllu = solver.net.blobs['illu'].data.copy()  #batch size illumination estimation result\n",
    "    #print solver.net.blobs['label'].data.copy() \n",
    "    #allGroundTruth = np.vstack((allGroundTruth, estimatedIllu))\n",
    "    #allImg = np.vstack((allImg, solver.net.blobs['data'].data.copy() ))\n",
    "    allAngulareErr = np.hstack((allAngulareErr, np.squeeze( multiangle(estimatedIllu, groundtruethIllu))))\n",
    "    #print np.shape(allAngulareErr)\n",
    "    #allAngulareErr = np.vstack((allAngulareErr, multiangle(estimatedIllu, groundtruethIllu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allAngulareErr)):\n",
    "    for j in range(len(allAngulareErr)):\n",
    "        if allAngulareErr[i] == allAngulareErr[j] and i != j:\n",
    "            print i\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9682476252972672, 3.8265616157506339, 4.1323755451534332, 0.044234659612636382, 12.550987553473167]\n"
     ]
    }
   ],
   "source": [
    "final_result =[];\n",
    "final_result.append(np.mean(allAngulareErr))\n",
    "final_result.append(np.median(allAngulareErr))\n",
    "final_result.append((np.percentile(allAngulareErr,25)+ np.percentile(allAngulareErr,75) + 2 *np.median(allAngulareErr))/4)\n",
    "final_result.append(np.amin(allAngulareErr))\n",
    "final_result.append(np.percentile(allAngulareErr,95))\n",
    "print final_result\n",
    "# fileName = \"final_result.txt\"\n",
    "# rmCommand = \"rm -rf /home/xca64/remote/data/\" + fileName\n",
    "# #os.system(rmCommand)\n",
    "# f = open('/home/xca64/remote/data/final_result.txt', 'a')\n",
    "# f.write(\"result for geler crossvalidation '1' 1 1 :\\n\")\n",
    "# f.write(str(final_result))\n",
    "# f.write(\"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(allAngulareErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = solver.net.blobs['data'].data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allImg = np.zeros([1,3,227,227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = allImg[162,...]\n",
    "plt.imshow(deprocess_net_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
